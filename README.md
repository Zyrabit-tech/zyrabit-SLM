# Zyrabit LLM Secure Suite

![Python](https://img.shields.io/badge/python-v3.10+-blue.svg)
![Docker](https://img.shields.io/badge/docker-compose-ready-green.svg)
![License](https://img.shields.io/badge/license-MIT-yellow.svg)
![Architecture](https://img.shields.io/badge/architecture-clean-orange.svg)

## ğŸ“– DescripciÃ³n del proyecto

**Zyrabit** es una soluciÃ³n completa de IA **Zeroâ€‘Trust** que combina:
- Un **servidor Ollama** local.
- Un **cliente Python** (`secure_agent.py`) que **sanitiza** cualquier prompt antes de enviarlo al modelo, evitando fugas de datos sensibles (PII, tarjetas, montos).
- Un **dashboard interactivo** construido con **Streamlit** (`app.py`) que muestra el prompt original y el prompt sanitizado, y visualiza la respuesta del modelo.
- Un **entorno Dockerâ€‘Compose** que orquesta el API RAG, Ollama, ChromaDB, Prometheus y Grafana.

El objetivo es demostrar cÃ³mo integrar **ciberseguridad ofensiva** en flujos de IA generativa sin sacrificar la usabilidad.

---

## ğŸ’° Por quÃ© Zyrabit (Value Proposition)

| CaracterÃ­stica | ğŸš« IA PÃºblica (ChatGPT/Claude) | âœ… Zyrabit (Local & Secure) |
| :--- | :--- | :--- |
| **Fuga de Datos** | Alto Riesgo (Tus datos entrenan sus modelos) | **Cero Riesgo** (SanitizaciÃ³n local + Air-Gapped) |
| **Costos Nube** | Recurrentes ($20/mes por usuario) | **$0 / mes** (Corre en tu propio hardware) |
| **Hardware** | Depende de servidores externos | **Optimizado** (Corre en CPU/GPU de consumo) |
| **Privacidad** | Caja Negra | **Auditable** (CÃ³digo Abierto 100%) |

---

## âœ¨ CaracterÃ­sticas principales

- **SanitizaciÃ³n automÃ¡tica** de correos, nÃºmeros de tarjetas de crÃ©dito y montos en dÃ³lares usando expresiones regulares.
- **ExposiciÃ³n del puerto Ollama (11434)** para que scripts locales puedan comunicarse con el modelo.
- **InstalaciÃ³n automÃ¡tica** del modelo `phi3` mediante el script `setup_ollama.sh`.
- **Interfaz grÃ¡fica** con Streamlit que muestra ladoâ€‘aâ€‘lado el texto antes y despuÃ©s de la sanitizaciÃ³n.
- **Monitoreo** con Prometheus y Grafana (puertos 9091 y 3000).
- **Persistencia** de modelos y vectores mediante volÃºmenes Docker (`./ollama-models`, `./chroma-data`).

---

## ğŸ—ï¸ Arquitectura

```mermaid
graph TD
    subgraph "Cliente Seguro (Python Local)"
        User((ğŸ‘¤ Usuario))
        Agent[ğŸ•µï¸ secure_agent.py<br/>(Sanitizer Regex/NER)]
        UI[ğŸ–¥ï¸ app.py<br/>(Streamlit Dashboard)]
    end

    subgraph "Zyrabit Core (Docker Network)"
        API[âš¡ api-rag<br/>(FastAPI Gateway)]
        LLM[ğŸ§  llm-server<br/>(Ollama - Phi3)]
        VectorDB[(ğŸ—„ï¸ ChromaDB<br/>Memoria Vectorial)]
        Monitor[ğŸ“Š Grafana + Prometheus<br/>Observabilidad]
    end

    User --> UI
    UI -->|1. Prompt Crudo| Agent
    Agent -->|2. Datos Redacted| API
    API -->|3. Query Vectorial| VectorDB
    VectorDB -->|4. Contexto| API
    API -->|5. Prompt Final| LLM
    LLM -->|6. Respuesta| API
    API -->|7. Display Seguro| UI

    style Agent fill:#ff9900,stroke:#333,stroke-width:2px
    style LLM fill:#99ff99,stroke:#333,stroke-width:2px
```

---

## ğŸš€ InstalaciÃ³n y puesta en marcha

### 1ï¸âƒ£ Prerrequisitos

- **Docker & Dockerâ€‘Compose**
- **Python 3.9+**
- **pip** (se usarÃ¡ `python3 -m pip` para evitar problemas de PATH)

### 2ï¸âƒ£ Clonar el repositorio

```bash
git clone https://github.com/tu-usuario/zyrabit-llm.git
cd zyrabit-llm
```

### 3ï¸âƒ£ Instalar dependencias Python

```bash
python3 -m pip install --user requests streamlit watchdog
```
> *Nota:* `streamlit` se instalÃ³ en `~/Library/Python/3.9/bin`. AÃ±ade esa ruta a tu `$PATH` si deseas usar el comando directamente:
```bash
export PATH="$HOME/Library/Python/3.9/bin:$PATH"
```

### 4ï¸âƒ£ Levantar los contenedores Docker

```bash
docker-compose up -d
```
Esto crearÃ¡ los servicios `api-rag`, `llm-server`, `vector-db`, `prometheus` y `grafana`.

### 5ï¸âƒ£ Descargar el modelo

Ejecuta el script de setup (descarga automÃ¡tica del modelo `phi3`):

```bash
chmod +x setup_ollama.sh
./setup_ollama.sh
```
El script verifica si el modelo ya estÃ¡ instalado y, de no ser asÃ­, lo descarga.

### 6ï¸âƒ£ Probar el cliente seguro

```bash
python3 secure_agent.py
```
DeberÃ­as ver dos casos de prueba: una pregunta inocente y una con datos sensibles que son redacted.

### 7ï¸âƒ£ Ejecutar la UI Streamlit

```bash
streamlit run app.py --server.headless true
```
Abre `http://localhost:8501` en tu navegador. La barra lateral muestra la configuraciÃ³n y el panel principal permite introducir prompts y ver el texto sanitizado y la respuesta del modelo.

---

## ğŸš‘ Troubleshooting

| Problema | SoluciÃ³n Posible |
| :--- | :--- |
| **Error: Connection refused** | AsegÃºrate de que Docker estÃ© corriendo (`docker ps`) y que el puerto 11434 estÃ© libre. |
| **Modelo no responde** | Ejecuta `./setup_ollama.sh` nuevamente para verificar que `phi3` se descargÃ³ correctamente. |
| **Streamlit no encontrado** | Revisa tu PATH o ejecuta `python3 -m streamlit run app.py`. |
| **Permisos denegados** | Ejecuta `chmod +x setup_ollama.sh` antes de correr el script. |

---

## ğŸ“„ Licencia

Este proyecto estÃ¡ bajo la **Licencia MIT**. Puedes usar, modificar y distribuir el cÃ³digo, incluso con fines comerciales, siempre que mantengas el aviso de licencia original.

---

## ğŸ™Œ Contribuciones

Las contribuciones son bienvenidas. Por favor, abre un *pull request* describiendo los cambios y asegurÃ¡ndote de que todas las pruebas pasen.

---

## ğŸ“ Contacto

**Zyrabit Systems** â€“ https://zyrabit.com


ğŸš§ PUBLIC BETA / EARLY ACCESS Este proyecto estÃ¡ en desarrollo activo. La arquitectura Core es estable, pero las interfaces pueden cambiar. Buscamos contribuidores valientes que quieran probar la "Seguridad Ofensiva" en sus propios entornos. Si rompes algo, abre un Issue. Si te gusta, danos una