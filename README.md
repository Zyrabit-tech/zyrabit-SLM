# Zyrabit LLM Secure Suite
![Python](https://img.shields.io/badge/python-v3.10+-blue.svg)
![Docker](https://img.shields.io/badge/docker--compose-ready-green.svg)
![License](https://img.shields.io/badge/license-MIT-yellow.svg)
![Architecture](https://img.shields.io/badge/architecture-clean-orange.svg)

**Zyrabit LLM Secure Suite** es una arquitectura de referencia para desplegar agentes de IA generativa seguros y privados en entornos empresariales. Combina la potencia de **Ollama (Phi-3)** con una capa de seguridad intermedia que sanitiza datos sensibles antes de que toquen el LLM.

## Arquitectura

```mermaid
graph TD
    subgraph "Cliente Seguro (Python Local)"
        User((üë§ Usuario))
        Agent["üïµÔ∏è secure_agent.py<br/>(Sanitizer Regex/NER)"]
        UI["üñ•Ô∏è app.py<br/>(Streamlit Dashboard)"]
    end

    subgraph "Zyrabit Core (Docker Network)"
        API["‚ö° api-rag<br/>(FastAPI Gateway)"]
        LLM["üß† llm-server<br/>(Ollama - Phi3)"]
        VectorDB[("üóÑÔ∏è ChromaDB<br/>Memoria Vectorial")]
        Monitor["üìä Grafana + Prometheus<br/>Observabilidad"]
    end

    User --> UI
    UI -->|1. Prompt Crudo| Agent
    Agent -->|2. Datos Redacted| API
    API -->|3. Query Vectorial| VectorDB
    VectorDB -->|4. Contexto| API
    API -->|5. Prompt Final| LLM
    LLM -->|6. Respuesta| API
    API -->|7. Display Seguro| UI

    style Agent fill:#ff9900,stroke:#333,stroke-width:2px
    style LLM fill:#99ff99,stroke:#333,stroke-width:2px
```

## Propuesta de Valor

1.  **Privacidad por Dise√±o**: Ning√∫n dato PII (Emails, Tel√©fonos, Tarjetas de Cr√©dito) llega al modelo de lenguaje. El agente seguro act√∫a como un firewall de datos.
2.  **Soberan√≠a de Datos**: Ejecuci√≥n 100% local u on-premise utilizando modelos eficientes como Phi-3.
3.  **Observabilidad Completa**: Stack de monitoreo integrado para trazar latencia, uso de tokens y errores en tiempo real.
4.  **Arquitectura Modular**: Componentes desacoplados (Cliente, API, LLM, VectorDB) que permiten escalar independientemente.

## Instalaci√≥n

### Prerrequisitos
*   Docker & Docker Compose
*   Python 3.10+
*   Ollama (para ejecuci√≥n local sin Docker)

### Pasos R√°pidos

1.  **Clonar el repositorio**:
    ```bash
    git clone https://github.com/tu-org/zyrabit-llm.git
    cd zyrabit-llm
    ```

2.  **Configurar Entorno**:
    ```bash
    # Instalar dependencias de Python
    pip install -r requirements.txt
    
    # Configurar Ollama y descargar modelo
    chmod +x setup_ollama.sh
    ./setup_ollama.sh
    ```

3.  **Ejecutar Agente Seguro**:
    ```bash
    python3 secure_agent.py
    ```

## Troubleshooting

*   **Error de conexi√≥n con Ollama**: Aseg√∫rate de que Ollama est√© corriendo (`ollama serve`) y escuchando en el puerto 11434.
*   **Modelo no encontrado**: Ejecuta `./setup_ollama.sh` para asegurar que `phi3` est√© descargado.
*   **Permisos de ejecuci√≥n**: Si `setup_ollama.sh` falla, aseg√∫rate de haber ejecutado `chmod +x setup_ollama.sh`.