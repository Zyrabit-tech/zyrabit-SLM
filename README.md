# Zyrabit SLM Secure Suite (v1.0â€‘beta)

[![English](https://img.shields.io/badge/lang-English-blue.svg)](README_EN.md)
![Python](https://img.shields.io/badge/python-v3.10%2B-blue.svg)
![Docker](https://img.shields.io/badge/docker--compose-ready-green.svg)
![License](https://img.shields.io/badge/license-MIT-yellow.svg)
![Architecture](https://img.shields.io/badge/architecture-clean-orange.svg)
![Tests](https://img.shields.io/badge/tests-passing-brightgreen.svg)

---

## ðŸ“– DescripciÃ³n

**Zyrabit SLM Secure Suite** es una soluciÃ³n de IA local que combina un modelo de lenguaje grande (Ollama) con un motor de recuperaciÃ³nâ€‘aumentada (RAG) y una capa de **Zeroâ€‘Trust** que sanitiza cualquier dato sensible antes de enviarlo al modelo. El proyecto estÃ¡ pensado para ejecutarse en entornos locales (Macâ€¯M1â€¯Pro, Linux, Windowsâ€¯WSL2) sin depender de la nube, garantizando privacidad y cumplimiento de normativas.

---

## ðŸ—ï¸ Arquitectura

```mermaid
graph TD
    subgraph "Cliente Seguro"
        User((ðŸ‘¤ Usuario))
        Agent["ðŸ•µï¸ secure_agent.py"]
        UI["ðŸ–¥ï¸ app.py (Streamlit)"]
    end
    subgraph "Zyrabit Core"
        API["âš¡ apiâ€‘rag"]
        SLM["ðŸ§  Ollama (Phi3 / Kimi)"]
        VectorDB[("ðŸ—„ï¸ ChromaDB")]
    end
    User --> UI
    UI -->|1. Prompt| Agent
    Agent -->|2. Sanitized| API
    API -->|3. RAG/Direct| SLM
    SLM --> VectorDB
```

---

## ðŸ› ï¸ Entorno Validado

| Plataforma | CPU | RAM | OS |
|------------|-----|-----|----|
| MacBookâ€¯Pro (M1â€¯Pro) | 8â€‘core | 16â€¯GB | macOSâ€¯Sequoiaâ€¯15.1 |
| Linux (Ubuntuâ€¯22.04) | 4â€‘core | 8â€¯GB | - |
| Windows (WSL2) | 4â€‘core | 8â€¯GB | - |

> **Nota Windows:** Use WSL2 para ejecutar Docker y los scripts.

---

## ðŸ“¦ InstalaciÃ³n

1. **Prerequisitos**
   - Dockerâ€¯&â€¯Dockerâ€‘Compose
   - Pythonâ€¯3.10â€¯+
   - `git` (opcional)
2. **Clonar el repositorio**
   ```bash
   git clone https://github.com/zyrabit/zyrabit-SLM.git
   cd zyrabit-SLM
   ```
3. **Entorno virtual**
   ```bash
   python -m venv .venv
   source .venv/bin/activate   # macOS / Linux
   # .venv\Scripts\activate   # Windows
   pip install -r requirements.txt
   ```
4. **Infraestructura**
   ```bash
   docker compose up -d   # levanta SLMâ€‘server, vectorâ€‘db y apiâ€‘rag
   ```
5. **Descargar modelos obligatorios**
   ```bash
   ./setup_ollama.sh   # verifica Docker, arranca SLMâ€‘server y descarga phi3, kimiâ€‘k2â€‘thinking:cloud y mxbaiâ€‘embedâ€‘large
   ```
6. **Ejecutar la UI**
   ```bash
   streamlit run app.py
   ```
   Accede a `http://localhost:8501`.

---

## ðŸš€ Uso rÃ¡pido

```bash
# CLI segura
python secure_agent.py "Mi email es juan@example.com y mi saldo es $1,200.00"
```

El agente mostrarÃ¡ el prompt original, el prompt sanitizado y la respuesta del modelo.

---

## ðŸ§ª Tests

Ejecuta la suite de pruebas con:
```bash
pytest -q
```
Los tests cubren la sanitizaciÃ³n de PII y la correcta respuesta del backend.

---

## ðŸ“œ Licencia

MIT Â© Zyrabit 2025